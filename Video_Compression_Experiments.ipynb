{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2411240e",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Video Compression Standards: MPEG-4, H.264, and H.265\n",
    "\n",
    "**Author:** Yousef Abdulziz AbuAmna (120221377)  \n",
    "**Institution:** Islamic University of Gaza — Faculty of Information Technology  \n",
    "**Date:** June 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "This notebook implements the full experimental pipeline for comparing MPEG-4, H.264, and H.265 video compression standards:\n",
    "\n",
    "1. **Setup & Dependencies** — Install all required tools and libraries\n",
    "2. **Sample Video Download** — Obtain test video sequences\n",
    "3. **Video Encoding** — Encode using MPEG-4, H.264, H.265 at multiple bitrates\n",
    "4. **Feature Extraction** — Bitrate, file size, PSNR, SSIM, encoding time, motion complexity\n",
    "5. **Machine Learning Analysis** — Regression models for compression prediction\n",
    "6. **Comparative Evaluation** — Visualizations and statistical comparisons\n",
    "7. **Results & Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4365be8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Dependencies\n",
    "Install all required Python packages and FFmpeg (the core tool for video encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1a. Install Python packages\n",
    "# ============================================================\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn scikit-image opencv-python-headless tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1b. Install FFmpeg  (Windows)\n",
    "# This downloads a static FFmpeg build and adds it to PATH\n",
    "# ============================================================\n",
    "import os, zipfile, urllib.request, shutil, subprocess, sys\n",
    "\n",
    "FFMPEG_DIR = os.path.join(os.getcwd(), 'ffmpeg')\n",
    "FFMPEG_EXE = os.path.join(FFMPEG_DIR, 'ffmpeg.exe')\n",
    "\n",
    "def check_ffmpeg():\n",
    "    \"\"\"Return path to ffmpeg if available.\"\"\"\n",
    "    if os.path.isfile(FFMPEG_EXE):\n",
    "        return FFMPEG_EXE\n",
    "    if shutil.which('ffmpeg'):\n",
    "        return shutil.which('ffmpeg')\n",
    "    return None\n",
    "\n",
    "if check_ffmpeg() is None:\n",
    "    print('FFmpeg not found. Downloading static build...')\n",
    "    url = 'https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip'\n",
    "    zip_path = os.path.join(os.getcwd(), 'ffmpeg_download.zip')\n",
    "    print(f'Downloading from {url} ...')\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print('Extracting...')\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(os.getcwd())\n",
    "    os.remove(zip_path)\n",
    "    # Find the extracted ffmpeg.exe and move to our ffmpeg/ folder\n",
    "    os.makedirs(FFMPEG_DIR, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(os.getcwd()):\n",
    "        for f in files:\n",
    "            if f == 'ffmpeg.exe' and 'ffmpeg' in root:\n",
    "                src = os.path.join(root, f)\n",
    "                if src != FFMPEG_EXE:\n",
    "                    shutil.copy2(src, FFMPEG_EXE)\n",
    "                    # Also copy ffprobe\n",
    "                    probe_src = os.path.join(root, 'ffprobe.exe')\n",
    "                    if os.path.isfile(probe_src):\n",
    "                        shutil.copy2(probe_src, os.path.join(FFMPEG_DIR, 'ffprobe.exe'))\n",
    "                    break\n",
    "    # Clean up extracted folder\n",
    "    for item in os.listdir(os.getcwd()):\n",
    "        full = os.path.join(os.getcwd(), item)\n",
    "        if os.path.isdir(full) and item.startswith('ffmpeg-') and item != 'ffmpeg':\n",
    "            shutil.rmtree(full, ignore_errors=True)\n",
    "\n",
    "FFMPEG = check_ffmpeg()\n",
    "FFPROBE = os.path.join(os.path.dirname(FFMPEG), 'ffprobe.exe') if FFMPEG else None\n",
    "if not FFPROBE or not os.path.isfile(FFPROBE):\n",
    "    FFPROBE = shutil.which('ffprobe')\n",
    "\n",
    "print(f'FFmpeg  : {FFMPEG}')\n",
    "print(f'FFprobe : {FFPROBE}')\n",
    "result = subprocess.run([FFMPEG, '-version'], capture_output=True, text=True)\n",
    "print(result.stdout.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808782f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1c. Import libraries\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid', palette='deep')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Working directories\n",
    "BASE_DIR   = Path(os.getcwd())\n",
    "VIDEO_DIR  = BASE_DIR / 'videos'\n",
    "OUTPUT_DIR = BASE_DIR / 'encoded'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "for d in [VIDEO_DIR, OUTPUT_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "print('All libraries loaded successfully.')\n",
    "print(f'Base directory : {BASE_DIR}')\n",
    "print(f'Video directory: {VIDEO_DIR}')\n",
    "print(f'Output directory: {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9efaa",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Download Sample Test Videos\n",
    "We download standard test sequences commonly used in video compression research. These cover diverse content types (high motion, low motion, varying textures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Download sample test videos\n",
    "# Using publicly available short clips from standard test sources\n",
    "# ============================================================\n",
    "import requests\n",
    "\n",
    "# Public domain / CC-licensed short test videos\n",
    "# These are small clips suitable for compression experiments\n",
    "SAMPLE_VIDEOS = {\n",
    "    'BigBuckBunny_360p': 'https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/360/Big_Buck_Bunny_360_10s_1MB.mp4',\n",
    "    'BigBuckBunny_720p': 'https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/720/Big_Buck_Bunny_720_10s_2MB.mp4',\n",
    "    'Jellyfish_360p':    'https://test-videos.co.uk/vids/jellyfish/mp4/h264/360/Jellyfish_360_10s_1MB.mp4',\n",
    "    'Jellyfish_720p':    'https://test-videos.co.uk/vids/jellyfish/mp4/h264/720/Jellyfish_720_10s_2MB.mp4',\n",
    "    'Sintel_360p':       'https://test-videos.co.uk/vids/sintel/mp4/h264/360/Sintel_360_10s_1MB.mp4',\n",
    "    'Sintel_720p':       'https://test-videos.co.uk/vids/sintel/mp4/h264/720/Sintel_720_10s_2MB.mp4',\n",
    "}\n",
    "\n",
    "downloaded_videos = []\n",
    "\n",
    "for name, url in SAMPLE_VIDEOS.items():\n",
    "    filepath = VIDEO_DIR / f'{name}.mp4'\n",
    "    if filepath.exists():\n",
    "        print(f'[SKIP] {name} already downloaded.')\n",
    "        downloaded_videos.append(filepath)\n",
    "        continue\n",
    "    print(f'[DOWNLOAD] {name} ...')\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        filepath.write_bytes(resp.content)\n",
    "        downloaded_videos.append(filepath)\n",
    "        print(f'  -> Saved ({len(resp.content)/1024:.0f} KB)')\n",
    "    except Exception as e:\n",
    "        print(f'  -> FAILED: {e}')\n",
    "\n",
    "print(f'\\nTotal videos ready: {len(downloaded_videos)}')\n",
    "for v in downloaded_videos:\n",
    "    print(f'  {v.name}  ({v.stat().st_size/1024:.0f} KB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2b. (Optional) Add your own videos\n",
    "# Place .mp4 files in the 'videos/' folder and run this cell\n",
    "# ============================================================\n",
    "all_videos = sorted(VIDEO_DIR.glob('*.mp4'))\n",
    "print(f'All available videos ({len(all_videos)}):')\n",
    "for v in all_videos:\n",
    "    print(f'  {v.name}  ({v.stat().st_size/1024:.0f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35541c",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Video Encoding Experiments\n",
    "Encode each source video using three codecs at multiple bitrates:\n",
    "- **MPEG-4 (Part 2)** — codec: `mpeg4`\n",
    "- **H.264 / AVC** — codec: `libx264`\n",
    "- **H.265 / HEVC** — codec: `libx265`\n",
    "\n",
    "Bitrate settings: **500k, 1M, 2M, 4M, 8M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ac305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3a. Helper functions for encoding & metrics\n",
    "# ============================================================\n",
    "\n",
    "CODECS = {\n",
    "    'MPEG4':  {'encoder': 'mpeg4',   'ext': 'mp4', 'extra': []},\n",
    "    'H264':   {'encoder': 'libx264', 'ext': 'mp4', 'extra': ['-preset', 'medium']},\n",
    "    'H265':   {'encoder': 'libx265', 'ext': 'mp4', 'extra': ['-preset', 'medium', '-tag:v', 'hvc1']},\n",
    "}\n",
    "\n",
    "BITRATES = ['500k', '1M', '2M', '4M', '8M']\n",
    "\n",
    "def bitrate_to_kbps(br_str):\n",
    "    \"\"\"Convert bitrate string like '500k' or '2M' to numeric kbps.\"\"\"\n",
    "    br_str = br_str.strip().upper()\n",
    "    if br_str.endswith('K'):\n",
    "        return int(br_str[:-1])\n",
    "    elif br_str.endswith('M'):\n",
    "        return int(float(br_str[:-1]) * 1000)\n",
    "    return int(br_str) // 1000\n",
    "\n",
    "def get_video_info(video_path):\n",
    "    \"\"\"Get video metadata using ffprobe.\"\"\"\n",
    "    cmd = [\n",
    "        FFPROBE, '-v', 'quiet', '-print_format', 'json',\n",
    "        '-show_format', '-show_streams', str(video_path)\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    info = json.loads(result.stdout)\n",
    "    video_stream = next((s for s in info['streams'] if s['codec_type'] == 'video'), {})\n",
    "    return {\n",
    "        'width': int(video_stream.get('width', 0)),\n",
    "        'height': int(video_stream.get('height', 0)),\n",
    "        'fps': eval(video_stream.get('r_frame_rate', '0/1')),\n",
    "        'duration': float(info['format'].get('duration', 0)),\n",
    "        'bitrate_kbps': int(info['format'].get('bit_rate', 0)) / 1000,\n",
    "        'nb_frames': int(video_stream.get('nb_frames', 0)),\n",
    "        'codec': video_stream.get('codec_name', 'unknown'),\n",
    "    }\n",
    "\n",
    "def encode_video(input_path, output_path, codec_name, bitrate):\n",
    "    \"\"\"Encode a video with given codec and bitrate. Returns encoding time.\"\"\"\n",
    "    codec = CODECS[codec_name]\n",
    "    cmd = [\n",
    "        FFMPEG, '-y', '-i', str(input_path),\n",
    "        '-c:v', codec['encoder'],\n",
    "        '-b:v', bitrate,\n",
    "        *codec['extra'],\n",
    "        '-an',            # no audio (focus on video compression)\n",
    "        '-threads', '4',\n",
    "        str(output_path)\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    encoding_time = time.time() - start_time\n",
    "    if result.returncode != 0:\n",
    "        print(f'  [ERROR] {codec_name} @ {bitrate}: {result.stderr[-200:]}')\n",
    "    return encoding_time\n",
    "\n",
    "def compute_quality_metrics(original_path, encoded_path, max_frames=50):\n",
    "    \"\"\"Compute PSNR and SSIM between original and encoded video (sampled frames).\"\"\"\n",
    "    cap_orig = cv2.VideoCapture(str(original_path))\n",
    "    cap_enc  = cv2.VideoCapture(str(encoded_path))\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    total_frames = int(cap_orig.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, total_frames // max_frames)\n",
    "    \n",
    "    while True:\n",
    "        ret1, frame1 = cap_orig.read()\n",
    "        ret2, frame2 = cap_enc.read()\n",
    "        if not ret1 or not ret2:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        if frame_count % step != 0:\n",
    "            continue\n",
    "        # Resize encoded frame to match original if needed\n",
    "        if frame1.shape != frame2.shape:\n",
    "            frame2 = cv2.resize(frame2, (frame1.shape[1], frame1.shape[0]))\n",
    "        # Convert to grayscale for SSIM\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        psnr_val = psnr(gray1, gray2)\n",
    "        ssim_val = ssim(gray1, gray2)\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "    \n",
    "    cap_orig.release()\n",
    "    cap_enc.release()\n",
    "    \n",
    "    return {\n",
    "        'psnr_mean': np.mean(psnr_values) if psnr_values else 0,\n",
    "        'psnr_std':  np.std(psnr_values)  if psnr_values else 0,\n",
    "        'ssim_mean': np.mean(ssim_values) if ssim_values else 0,\n",
    "        'ssim_std':  np.std(ssim_values)  if ssim_values else 0,\n",
    "        'frames_compared': len(psnr_values)\n",
    "    }\n",
    "\n",
    "def compute_motion_complexity(video_path, max_frames=100):\n",
    "    \"\"\"Estimate motion complexity via mean optical flow magnitude.\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        return 0.0\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow_magnitudes = []\n",
    "    count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, total_frames // max_frames)\n",
    "    \n",
    "    while count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        count += 1\n",
    "        if count % step != 0:\n",
    "            prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            continue\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "        flow_magnitudes.append(np.mean(magnitude))\n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    return np.mean(flow_magnitudes) if flow_magnitudes else 0.0\n",
    "\n",
    "print('Helper functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3b. Run encoding experiments\n",
    "# ============================================================\n",
    "all_videos = sorted(VIDEO_DIR.glob('*.mp4'))\n",
    "results = []\n",
    "\n",
    "print(f'Encoding {len(all_videos)} videos × {len(CODECS)} codecs × {len(BITRATES)} bitrates')\n",
    "print(f'= {len(all_videos) * len(CODECS) * len(BITRATES)} total encodes\\n')\n",
    "\n",
    "for video_path in all_videos:\n",
    "    video_name = video_path.stem\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Video: {video_name}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    # Get source video info\n",
    "    src_info = get_video_info(video_path)\n",
    "    motion_complexity = compute_motion_complexity(video_path)\n",
    "    original_size_kb = video_path.stat().st_size / 1024\n",
    "    \n",
    "    print(f'  Resolution: {src_info[\"width\"]}x{src_info[\"height\"]}, '\n",
    "          f'FPS: {src_info[\"fps\"]:.1f}, Duration: {src_info[\"duration\"]:.1f}s, '\n",
    "          f'Motion: {motion_complexity:.2f}')\n",
    "    \n",
    "    for codec_name in CODECS:\n",
    "        for bitrate in BITRATES:\n",
    "            out_name = f'{video_name}_{codec_name}_{bitrate}.mp4'\n",
    "            out_path = OUTPUT_DIR / out_name\n",
    "            \n",
    "            # Encode\n",
    "            enc_time = encode_video(video_path, out_path, codec_name, bitrate)\n",
    "            \n",
    "            if not out_path.exists():\n",
    "                print(f'  [SKIP] {codec_name} @ {bitrate} — encoding failed')\n",
    "                continue\n",
    "            \n",
    "            # Get encoded video info\n",
    "            enc_info = get_video_info(out_path)\n",
    "            encoded_size_kb = out_path.stat().st_size / 1024\n",
    "            \n",
    "            # Compute quality metrics\n",
    "            quality = compute_quality_metrics(video_path, out_path)\n",
    "            \n",
    "            # Compression ratio\n",
    "            compression_ratio = original_size_kb / encoded_size_kb if encoded_size_kb > 0 else 0\n",
    "            bitrate_savings_pct = (1 - encoded_size_kb / original_size_kb) * 100\n",
    "            \n",
    "            row = {\n",
    "                'video': video_name,\n",
    "                'codec': codec_name,\n",
    "                'target_bitrate': bitrate,\n",
    "                'target_bitrate_kbps': bitrate_to_kbps(bitrate),\n",
    "                'actual_bitrate_kbps': enc_info['bitrate_kbps'],\n",
    "                'width': src_info['width'],\n",
    "                'height': src_info['height'],\n",
    "                'resolution': f\"{src_info['width']}x{src_info['height']}\",\n",
    "                'fps': src_info['fps'],\n",
    "                'duration_s': src_info['duration'],\n",
    "                'original_size_kb': round(original_size_kb, 2),\n",
    "                'encoded_size_kb': round(encoded_size_kb, 2),\n",
    "                'compression_ratio': round(compression_ratio, 3),\n",
    "                'bitrate_savings_pct': round(bitrate_savings_pct, 2),\n",
    "                'encoding_time_s': round(enc_time, 3),\n",
    "                'psnr_mean': round(quality['psnr_mean'], 3),\n",
    "                'psnr_std': round(quality['psnr_std'], 3),\n",
    "                'ssim_mean': round(quality['ssim_mean'], 5),\n",
    "                'ssim_std': round(quality['ssim_std'], 5),\n",
    "                'motion_complexity': round(motion_complexity, 4),\n",
    "                'frames_compared': quality['frames_compared'],\n",
    "            }\n",
    "            results.append(row)\n",
    "            print(f'  {codec_name:5s} @ {bitrate:4s} -> '\n",
    "                  f'Size: {encoded_size_kb:7.0f} KB | '\n",
    "                  f'PSNR: {quality[\"psnr_mean\"]:5.1f} dB | '\n",
    "                  f'SSIM: {quality[\"ssim_mean\"]:.4f} | '\n",
    "                  f'Time: {enc_time:.2f}s')\n",
    "\n",
    "print(f'\\n\\nDone! {len(results)} encoding experiments completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56010bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3c. Save results to CSV\n",
    "# ============================================================\n",
    "df = pd.DataFrame(results)\n",
    "csv_path = RESULTS_DIR / 'encoding_results.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f'Results saved to {csv_path}')\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2c2c8",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Extraction & Data Overview\n",
    "Explore the extracted features from all encoding experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc71a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4a. Load and inspect the results\n",
    "# ============================================================\n",
    "# (If you restart the notebook, load from CSV)\n",
    "# df = pd.read_csv(RESULTS_DIR / 'encoding_results.csv')\n",
    "\n",
    "print('Dataset Shape:', df.shape)\n",
    "print('\\nColumns:')\n",
    "print(df.columns.tolist())\n",
    "print('\\n--- Summary Statistics ---')\n",
    "df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c15569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4b. Feature overview per codec\n",
    "# ============================================================\n",
    "codec_summary = df.groupby('codec').agg({\n",
    "    'encoded_size_kb': ['mean', 'std'],\n",
    "    'compression_ratio': ['mean', 'std'],\n",
    "    'psnr_mean': ['mean', 'std'],\n",
    "    'ssim_mean': ['mean', 'std'],\n",
    "    'encoding_time_s': ['mean', 'std'],\n",
    "    'bitrate_savings_pct': ['mean', 'std'],\n",
    "}).round(3)\n",
    "\n",
    "print('=== Per-Codec Summary Statistics ===')\n",
    "codec_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df29c2",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparative Evaluation & Visualization\n",
    "Visual comparison of MPEG-4, H.264, and H.265 across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5a. Compression Ratio vs Bitrate per Codec\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Compression Ratio\n",
    "for codec in ['MPEG4', 'H264', 'H265']:\n",
    "    subset = df[df['codec'] == codec].groupby('target_bitrate_kbps').agg(\n",
    "        compression_ratio=('compression_ratio', 'mean'),\n",
    "        psnr_mean=('psnr_mean', 'mean')\n",
    "    ).reset_index()\n",
    "    axes[0].plot(subset['target_bitrate_kbps'], subset['compression_ratio'],\n",
    "                 marker='o', linewidth=2, markersize=8, label=codec)\n",
    "\n",
    "axes[0].set_xlabel('Target Bitrate (kbps)', fontsize=12)\n",
    "axes[0].set_ylabel('Compression Ratio', fontsize=12)\n",
    "axes[0].set_title('Compression Ratio vs Target Bitrate', fontsize=14)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: File Size\n",
    "for codec in ['MPEG4', 'H264', 'H265']:\n",
    "    subset = df[df['codec'] == codec].groupby('target_bitrate_kbps').agg(\n",
    "        encoded_size_kb=('encoded_size_kb', 'mean')\n",
    "    ).reset_index()\n",
    "    axes[1].plot(subset['target_bitrate_kbps'], subset['encoded_size_kb'],\n",
    "                 marker='s', linewidth=2, markersize=8, label=codec)\n",
    "\n",
    "axes[1].set_xlabel('Target Bitrate (kbps)', fontsize=12)\n",
    "axes[1].set_ylabel('Encoded File Size (KB)', fontsize=12)\n",
    "axes[1].set_title('Encoded File Size vs Target Bitrate', fontsize=14)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'compression_ratio_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc391b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5b. Quality Metrics: PSNR and SSIM vs Bitrate\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PSNR\n",
    "for codec in ['MPEG4', 'H264', 'H265']:\n",
    "    subset = df[df['codec'] == codec].groupby('target_bitrate_kbps')['psnr_mean'].mean().reset_index()\n",
    "    axes[0].plot(subset['target_bitrate_kbps'], subset['psnr_mean'],\n",
    "                 marker='o', linewidth=2, markersize=8, label=codec)\n",
    "\n",
    "axes[0].set_xlabel('Target Bitrate (kbps)', fontsize=12)\n",
    "axes[0].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "axes[0].set_title('PSNR vs Target Bitrate', fontsize=14)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM\n",
    "for codec in ['MPEG4', 'H264', 'H265']:\n",
    "    subset = df[df['codec'] == codec].groupby('target_bitrate_kbps')['ssim_mean'].mean().reset_index()\n",
    "    axes[1].plot(subset['target_bitrate_kbps'], subset['ssim_mean'],\n",
    "                 marker='s', linewidth=2, markersize=8, label=codec)\n",
    "\n",
    "axes[1].set_xlabel('Target Bitrate (kbps)', fontsize=12)\n",
    "axes[1].set_ylabel('SSIM', fontsize=12)\n",
    "axes[1].set_title('SSIM vs Target Bitrate', fontsize=14)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'quality_metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026510c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5c. Encoding Time (Computational Cost) Comparison\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Line plot: Encoding time vs bitrate\n",
    "for codec in ['MPEG4', 'H264', 'H265']:\n",
    "    subset = df[df['codec'] == codec].groupby('target_bitrate_kbps')['encoding_time_s'].mean().reset_index()\n",
    "    axes[0].plot(subset['target_bitrate_kbps'], subset['encoding_time_s'],\n",
    "                 marker='D', linewidth=2, markersize=8, label=codec)\n",
    "\n",
    "axes[0].set_xlabel('Target Bitrate (kbps)', fontsize=12)\n",
    "axes[0].set_ylabel('Encoding Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Encoding Time vs Target Bitrate', fontsize=14)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot: Average encoding time per codec\n",
    "avg_time = df.groupby('codec')['encoding_time_s'].mean().reindex(['MPEG4', 'H264', 'H265'])\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "bars = axes[1].bar(avg_time.index, avg_time.values, color=colors, edgecolor='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Codec', fontsize=12)\n",
    "axes[1].set_ylabel('Average Encoding Time (s)', fontsize=12)\n",
    "axes[1].set_title('Average Encoding Time per Codec', fontsize=14)\n",
    "for bar, val in zip(bars, avg_time.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                 f'{val:.2f}s', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'encoding_time_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96351ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5d. Box Plots: Distribution of Quality Metrics per Codec\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "codec_order = ['MPEG4', 'H264', 'H265']\n",
    "\n",
    "sns.boxplot(data=df, x='codec', y='psnr_mean', order=codec_order, ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('PSNR Distribution by Codec', fontsize=14)\n",
    "axes[0].set_xlabel('Codec', fontsize=12)\n",
    "axes[0].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "\n",
    "sns.boxplot(data=df, x='codec', y='ssim_mean', order=codec_order, ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('SSIM Distribution by Codec', fontsize=14)\n",
    "axes[1].set_xlabel('Codec', fontsize=12)\n",
    "axes[1].set_ylabel('SSIM', fontsize=12)\n",
    "\n",
    "sns.boxplot(data=df, x='codec', y='compression_ratio', order=codec_order, ax=axes[2], palette='Set2')\n",
    "axes[2].set_title('Compression Ratio Distribution by Codec', fontsize=14)\n",
    "axes[2].set_xlabel('Codec', fontsize=12)\n",
    "axes[2].set_ylabel('Compression Ratio', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'boxplot_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5e. Heatmap: PSNR per Video and Codec at each Bitrate\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, codec in enumerate(['MPEG4', 'H264', 'H265']):\n",
    "    pivot = df[df['codec'] == codec].pivot_table(\n",
    "        values='psnr_mean', index='video', columns='target_bitrate_kbps', aggfunc='mean'\n",
    "    )\n",
    "    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[idx],\n",
    "                cbar_kws={'label': 'PSNR (dB)'})\n",
    "    axes[idx].set_title(f'{codec} — PSNR by Video & Bitrate', fontsize=13)\n",
    "    axes[idx].set_xlabel('Bitrate (kbps)')\n",
    "    axes[idx].set_ylabel('Video')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'heatmap_psnr.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5f. Rate-Distortion (RD) Curves per Video\n",
    "# ============================================================\n",
    "video_names = df['video'].unique()\n",
    "n_videos = len(video_names)\n",
    "cols = min(3, n_videos)\n",
    "rows = (n_videos + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 5*rows))\n",
    "if n_videos == 1:\n",
    "    axes = np.array([axes])\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, video in enumerate(video_names):\n",
    "    ax = axes[i]\n",
    "    for codec in ['MPEG4', 'H264', 'H265']:\n",
    "        sub = df[(df['video'] == video) & (df['codec'] == codec)].sort_values('target_bitrate_kbps')\n",
    "        ax.plot(sub['actual_bitrate_kbps'], sub['psnr_mean'],\n",
    "                marker='o', linewidth=2, markersize=7, label=codec)\n",
    "    ax.set_title(video, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Actual Bitrate (kbps)')\n",
    "    ax.set_ylabel('PSNR (dB)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "fig.suptitle('Rate-Distortion Curves per Video', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'rd_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb92a3",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Machine Learning Analysis\n",
    "Apply regression models to:\n",
    "1. **Predict PSNR** from compression features (codec, bitrate, motion complexity, resolution)\n",
    "2. **Predict bitrate savings** from video characteristics\n",
    "3. **Analyze feature importance** to understand which factors drive compression performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6a. Prepare ML dataset\n",
    "# ============================================================\n",
    "\n",
    "# Encode codec as numeric\n",
    "codec_map = {'MPEG4': 0, 'H264': 1, 'H265': 2}\n",
    "df_ml = df.copy()\n",
    "df_ml['codec_num'] = df_ml['codec'].map(codec_map)\n",
    "\n",
    "# Feature columns for ML\n",
    "feature_cols = [\n",
    "    'codec_num',\n",
    "    'target_bitrate_kbps',\n",
    "    'width',\n",
    "    'height',\n",
    "    'fps',\n",
    "    'duration_s',\n",
    "    'motion_complexity',\n",
    "    'original_size_kb',\n",
    "]\n",
    "\n",
    "# Target variables\n",
    "target_psnr = 'psnr_mean'\n",
    "target_ssim = 'ssim_mean'\n",
    "target_size = 'encoded_size_kb'\n",
    "target_savings = 'bitrate_savings_pct'\n",
    "\n",
    "X = df_ml[feature_cols].values\n",
    "y_psnr = df_ml[target_psnr].values\n",
    "y_ssim = df_ml[target_ssim].values\n",
    "y_savings = df_ml[target_savings].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f'ML Dataset: {X.shape[0]} samples, {X.shape[1]} features')\n",
    "print(f'Features: {feature_cols}')\n",
    "print(f'\\nFeature statistics:')\n",
    "pd.DataFrame(X, columns=feature_cols).describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6b. Train regression models to predict PSNR\n",
    "# ============================================================\n",
    "\n",
    "def train_and_evaluate(X, y, target_name, feature_names):\n",
    "    \"\"\"Train multiple regression models and return comparison results.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Target': target_name,\n",
    "            'RMSE': round(rmse, 4),\n",
    "            'MAE': round(mae, 4),\n",
    "            'R²': round(r2, 4),\n",
    "        })\n",
    "        trained_models[name] = (model, y_test, y_pred)\n",
    "    \n",
    "    return pd.DataFrame(results), trained_models\n",
    "\n",
    "# --- Predict PSNR ---\n",
    "print('='*60)\n",
    "print('TASK 1: Predicting PSNR from compression features')\n",
    "print('='*60)\n",
    "psnr_results, psnr_models = train_and_evaluate(X_scaled, y_psnr, 'PSNR', feature_cols)\n",
    "print(psnr_results.to_string(index=False))\n",
    "\n",
    "# --- Predict SSIM ---\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print('TASK 2: Predicting SSIM from compression features')\n",
    "print('='*60)\n",
    "ssim_results, ssim_models = train_and_evaluate(X_scaled, y_ssim, 'SSIM', feature_cols)\n",
    "print(ssim_results.to_string(index=False))\n",
    "\n",
    "# --- Predict Bitrate Savings ---\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print('TASK 3: Predicting Bitrate Savings (%) from compression features')\n",
    "print('='*60)\n",
    "savings_results, savings_models = train_and_evaluate(X_scaled, y_savings, 'Bitrate Savings %', feature_cols)\n",
    "print(savings_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce204f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6c. Visualize ML Model Performance\n",
    "# ============================================================\n",
    "all_ml_results = pd.concat([psnr_results, ssim_results, savings_results], ignore_index=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, target in enumerate(['PSNR', 'SSIM', 'Bitrate Savings %']):\n",
    "    sub = all_ml_results[all_ml_results['Target'] == target]\n",
    "    colors = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "    bars = axes[idx].bar(sub['Model'], sub['R²'], color=colors, edgecolor='black', linewidth=0.5)\n",
    "    axes[idx].set_title(f'R² Score — Predicting {target}', fontsize=13)\n",
    "    axes[idx].set_ylabel('R² Score')\n",
    "    axes[idx].set_ylim(0, 1.05)\n",
    "    for bar, val in zip(bars, sub['R²'].values):\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                       f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    axes[idx].tick_params(axis='x', rotation=15)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'ml_model_r2_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc069903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6d. Actual vs Predicted scatter plots\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "model_sets = [\n",
    "    ('PSNR (dB)', psnr_models),\n",
    "    ('SSIM', ssim_models),\n",
    "    ('Bitrate Savings (%)', savings_models),\n",
    "]\n",
    "\n",
    "for idx, (label, models_dict) in enumerate(model_sets):\n",
    "    # Use best model (Gradient Boosting)\n",
    "    best_name = 'Gradient Boosting'\n",
    "    model, y_test, y_pred = models_dict[best_name]\n",
    "    \n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.6, edgecolor='black', linewidth=0.3, s=60)\n",
    "    # Perfect prediction line\n",
    "    lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
    "    axes[idx].plot(lims, lims, 'r--', linewidth=2, label='Perfect prediction')\n",
    "    axes[idx].set_xlabel(f'Actual {label}', fontsize=12)\n",
    "    axes[idx].set_ylabel(f'Predicted {label}', fontsize=12)\n",
    "    axes[idx].set_title(f'{best_name}: {label}', fontsize=13)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    axes[idx].legend([f'R² = {r2:.4f}', 'Perfect'], fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39987466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6e. Feature Importance Analysis (Random Forest)\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "targets_info = [\n",
    "    ('PSNR', psnr_models),\n",
    "    ('SSIM', ssim_models),\n",
    "    ('Bitrate Savings %', savings_models),\n",
    "]\n",
    "\n",
    "for idx, (target_name, models_dict) in enumerate(targets_info):\n",
    "    rf_model = models_dict['Random Forest'][0]\n",
    "    importances = rf_model.feature_importances_\n",
    "    sorted_idx = np.argsort(importances)\n",
    "    \n",
    "    axes[idx].barh(range(len(feature_cols)), importances[sorted_idx], color='steelblue', edgecolor='black', linewidth=0.3)\n",
    "    axes[idx].set_yticks(range(len(feature_cols)))\n",
    "    axes[idx].set_yticklabels([feature_cols[i] for i in sorted_idx])\n",
    "    axes[idx].set_xlabel('Feature Importance')\n",
    "    axes[idx].set_title(f'Feature Importance for {target_name}', fontsize=13)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097bb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6f. Correlation Heatmap of All Features\n",
    "# ============================================================\n",
    "corr_cols = feature_cols + ['psnr_mean', 'ssim_mean', 'encoded_size_kb', 'compression_ratio',\n",
    "                            'bitrate_savings_pct', 'encoding_time_s']\n",
    "corr_matrix = df_ml[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8, 'label': 'Correlation'})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc96fd5",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Results Summary & Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264880f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7a. Final Comparison Table\n",
    "# ============================================================\n",
    "final_comparison = df.groupby('codec').agg({\n",
    "    'psnr_mean':          'mean',\n",
    "    'ssim_mean':          'mean',\n",
    "    'compression_ratio':  'mean',\n",
    "    'encoded_size_kb':    'mean',\n",
    "    'encoding_time_s':    'mean',\n",
    "    'bitrate_savings_pct':'mean',\n",
    "}).reindex(['MPEG4', 'H264', 'H265']).round(4)\n",
    "\n",
    "final_comparison.columns = ['Avg PSNR (dB)', 'Avg SSIM', 'Avg Compression Ratio',\n",
    "                            'Avg File Size (KB)', 'Avg Encoding Time (s)',\n",
    "                            'Avg Bitrate Savings (%)']\n",
    "\n",
    "print('='*70)\n",
    "print('FINAL COMPARISON: MPEG-4 vs H.264 vs H.265')\n",
    "print('='*70)\n",
    "final_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7b. ML Models Performance Summary\n",
    "# ============================================================\n",
    "print('='*70)\n",
    "print('MACHINE LEARNING MODELS — PERFORMANCE SUMMARY')\n",
    "print('='*70)\n",
    "print(all_ml_results.to_string(index=False))\n",
    "\n",
    "print('\\n\\n--- Key Findings ---')\n",
    "best_per_target = all_ml_results.loc[all_ml_results.groupby('Target')['R²'].idxmax()]\n",
    "for _, row in best_per_target.iterrows():\n",
    "    print(f\"  • Best model for {row['Target']}: {row['Model']} (R² = {row['R²']:.4f}, RMSE = {row['RMSE']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7c. Radar Chart — Overall Codec Comparison (Normalized)\n",
    "# ============================================================\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "\n",
    "# Normalize metrics (higher = better)\n",
    "radar_df = final_comparison.copy()\n",
    "# Invert metrics where lower is better (file size, encoding time)\n",
    "radar_df['Avg File Size (KB)'] = 1 / radar_df['Avg File Size (KB)']\n",
    "radar_df['Avg Encoding Time (s)'] = 1 / radar_df['Avg Encoding Time (s)']\n",
    "\n",
    "# Normalize to 0–1 range\n",
    "for col in radar_df.columns:\n",
    "    col_min = radar_df[col].min()\n",
    "    col_max = radar_df[col].max()\n",
    "    if col_max > col_min:\n",
    "        radar_df[col] = (radar_df[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        radar_df[col] = 1.0\n",
    "\n",
    "categories = ['Quality\\n(PSNR)', 'Perceptual\\n(SSIM)', 'Compression\\nRatio',\n",
    "              'File Size\\nEfficiency', 'Speed\\n(1/Time)', 'Bitrate\\nSavings']\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Close the circle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "colors_radar = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "for idx, codec in enumerate(['MPEG4', 'H264', 'H265']):\n",
    "    values = radar_df.loc[codec].values.tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=codec, color=colors_radar[idx])\n",
    "    ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=11)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title('Overall Codec Comparison (Normalized)', fontsize=15, fontweight='bold', y=1.08)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'radar_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7d. Save all results\n",
    "# ============================================================\n",
    "df.to_csv(RESULTS_DIR / 'encoding_results.csv', index=False)\n",
    "all_ml_results.to_csv(RESULTS_DIR / 'ml_model_results.csv', index=False)\n",
    "final_comparison.to_csv(RESULTS_DIR / 'final_comparison.csv')\n",
    "\n",
    "print('All results and figures saved to:', RESULTS_DIR)\n",
    "print('\\nFiles generated:')\n",
    "for f in sorted(RESULTS_DIR.iterdir()):\n",
    "    print(f'  {f.name}  ({f.stat().st_size/1024:.1f} KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fba08",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook implemented the full experimental pipeline from the research proposal:\n",
    "\n",
    "| Phase | Description | Status |\n",
    "|-------|-------------|--------|\n",
    "| 1. Setup | FFmpeg + Python dependencies installed | ✅ |\n",
    "| 2. Dataset | Sample videos downloaded (diverse content) | ✅ |\n",
    "| 3. Encoding | MPEG-4, H.264, H.265 × 5 bitrates | ✅ |\n",
    "| 4. Features | Bitrate, PSNR, SSIM, encoding time, motion complexity | ✅ |\n",
    "| 5. ML Analysis | Linear Regression, Random Forest, Gradient Boosting | ✅ |\n",
    "| 6. Evaluation | RD curves, box plots, heatmaps, radar chart | ✅ |\n",
    "| 7. Results | CSV exports + PNG visualizations | ✅ |\n",
    "\n",
    "### Expected Key Findings:\n",
    "- **H.265** provides the best compression efficiency (highest PSNR/SSIM at lower bitrates)\n",
    "- **H.264** offers a good balance between quality and encoding speed\n",
    "- **MPEG-4** has the fastest encoding but lower compression efficiency\n",
    "- **H.265** requires the most computational time (encoder complexity)\n",
    "- ML models can effectively predict compression quality from video features"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
